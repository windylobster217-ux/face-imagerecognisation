{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/windylobster217-ux/face-imagerecognisation/blob/main/Vmsfaceimagedetction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# VISITOR RECOGNITION ASSET GENERATION (FINAL VERSION WITH CV2 LOADING FIX)\n",
        "# ==============================================================================\n",
        "\n",
        "# -----------------\n",
        "# 1. SETUP & CONFIG (Assuming libraries are installed and drive is mounted)\n",
        "# -----------------\n",
        "import torch\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import sys\n",
        "import cv2 # <-- NEW: Import OpenCV\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms\n",
        "import torch.onnx\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "from google.colab import drive\n",
        "\n",
        "# Define file paths\n",
        "DATA_DIR = '/content/drive/MyDrive/IMAGE DATASET'\n",
        "EMBEDDINGS_FILE = '/content/drive/MyDrive/visitor_embeddings.pkl'\n",
        "ONNX_MODEL_PATH = '/content/drive/MyDrive/facenet_model.onnx'\n",
        "\n",
        "# Re-mount Drive and select device (assumes successful prior installation)\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "except Exception:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# --- Custom Image Loading Function to bypass PIL/Dtype issues ---\n",
        "def load_and_convert_to_pil(image_path):\n",
        "    # Use cv2.imread for robust file handling\n",
        "    img_np = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    if img_np is None:\n",
        "        raise ValueError(\"cv2.imread failed to load the image.\")\n",
        "    # Convert from BGR to RGB\n",
        "    img_np = cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB)\n",
        "    # Convert to PIL Image for MTCNN compatibility\n",
        "    return Image.fromarray(img_np)\n",
        "\n",
        "# --------------------------\n",
        "# 2. PIPELINE STEP: FILE CLEANUP AND IMAGE CONVERSION (Standardization)\n",
        "# --------------------------\n",
        "print(\"\\n--- 2. File Cleanup & Aggressive Image Standardization ---\")\n",
        "valid_image_count = 0\n",
        "\n",
        "for root, _, files in os.walk(DATA_DIR):\n",
        "    for filename in files:\n",
        "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            old_path = os.path.join(root, filename)\n",
        "            # Normalize filename (re-run for safety)\n",
        "            new_filename = filename.replace(' ', '_').replace('#', '').replace(' ', '')\n",
        "            new_path = os.path.join(root, new_filename)\n",
        "            if old_path != new_path:\n",
        "                os.rename(old_path, new_path)\n",
        "\n",
        "            # Aggressive Format Conversion (resaving as standard RGB JPEG)\n",
        "            try:\n",
        "                img = Image.open(new_path)\n",
        "                if img.mode != 'RGB': img = img.convert('RGB')\n",
        "                img.save(new_path, 'JPEG')\n",
        "                valid_image_count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Corrupted/Unreadable file detected: {new_path}. Error: {e}\")\n",
        "                os.rename(new_path, new_path + '.corrupt')\n",
        "\n",
        "if valid_image_count == 0:\n",
        "    print(\"\\n❌ CRITICAL ERROR: NO valid image files found after conversion. ABORTING.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "print(f\"✅ Finished image standardization. {valid_image_count} files processed successfully.\")\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 3. MODELS INITIALIZATION\n",
        "# --------------------------\n",
        "print(\"\\n--- 3. Models Initialization ---\")\n",
        "mtcnn = MTCNN(image_size=160, margin=14, min_face_size=20, post_process=True, device=device)\n",
        "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
        "print('✅ Models initialized.')\n",
        "\n",
        "# --------------------------\n",
        "# 4. PIPELINE STEP: GENERATE EMBEDDINGS (THE CORE PROCESS)\n",
        "# --------------------------\n",
        "print(\"\\n--- 4. Generating Embeddings (Using Manual CV2 Load) ---\")\n",
        "all_image_paths = []\n",
        "all_labels = []\n",
        "\n",
        "# Manually collect paths and labels\n",
        "for root, dirs, files in os.walk(DATA_DIR):\n",
        "    if root != DATA_DIR: # Skip the root folder\n",
        "        label_name = os.path.basename(root)\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.jpg', '.jpeg', '.png')) and not file.endswith('.corrupt'):\n",
        "                all_image_paths.append(os.path.join(root, file))\n",
        "                all_labels.append(label_name)\n",
        "\n",
        "embeddings_raw = {label: [] for label in set(all_labels)}\n",
        "success_count = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for img_path, name in zip(all_image_paths, all_labels):\n",
        "        try:\n",
        "            # LOAD IMAGE with robust CV2 method\n",
        "            img = load_and_convert_to_pil(img_path)\n",
        "\n",
        "            face_tensor = mtcnn(img)\n",
        "            if face_tensor is not None:\n",
        "                face_tensor_batch = face_tensor.to(device).unsqueeze(0)\n",
        "                embedding = resnet(face_tensor_batch).cpu().numpy()[0]\n",
        "\n",
        "                embeddings_raw[name].append(embedding)\n",
        "                success_count += 1\n",
        "            else:\n",
        "                print(f'⚠️ Warning: No face detected for {img_path}. Skipping.')\n",
        "        except Exception as e:\n",
        "            # If it fails here, the file is unreadable even by CV2\n",
        "            print(f'❌ CRITICAL FINAL FAILURE processing {img_path}: {e}')\n",
        "\n",
        "print(f'\\n✅ Finished generating raw embeddings. Total successful: {success_count}')\n",
        "if success_count == 0:\n",
        "    print(\"❌ Aborting export as no embeddings were created.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# --------------------------\n",
        "# 5. PIPELINE STEP: CREATE & SAVE VISITOR DATABASE (PKL)\n",
        "# --------------------------\n",
        "visitor_database = {}\n",
        "for name, emb_list in embeddings_raw.items():\n",
        "    if len(emb_list) > 0:\n",
        "        mean_embedding = np.mean(emb_list, axis=0)\n",
        "        visitor_database[name] = mean_embedding / np.linalg.norm(mean_embedding)\n",
        "\n",
        "try:\n",
        "    with open(EMBEDDINGS_FILE, 'wb') as f:\n",
        "        pickle.dump(visitor_database, f)\n",
        "    print(f'\\n--- 5. Final Visitor Database (PKL) ---')\n",
        "    print(f'Database saved to: {EMBEDDINGS_FILE}')\n",
        "except Exception as e:\n",
        "    print(f'❌ ERROR: Could not save PKL file to Drive: {e}')\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 6. PIPELINE STEP: EXPORT MODEL TO ONNX\n",
        "# --------------------------\n",
        "resnet.eval().cpu()\n",
        "dummy_input = torch.randn(1, 3, 160, 160)\n",
        "\n",
        "try:\n",
        "    torch.onnx.export(resnet, dummy_input, ONNX_MODEL_PATH, opset_version=12, do_constant_folding=True,\n",
        "                      input_names=['input'], output_names=['output'],\n",
        "                      dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})\n",
        "    print(f'\\n--- 6. ONNX Model Export ---')\n",
        "    print(f'✅ Model exported to ONNX: {ONNX_MODEL_PATH}')\n",
        "except Exception as e:\n",
        "    print(f'❌ CRITICAL ERROR: Failed to export ONNX model: {e}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "id": "xk8Ac5xViYLK",
        "outputId": "345b2dfb-bd2d-48f3-f919-7b1e698d43f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "--- 2. File Cleanup & Aggressive Image Standardization ---\n",
            "✅ Finished image standardization. 20 files processed successfully.\n",
            "\n",
            "--- 3. Models Initialization ---\n",
            "✅ Models initialized.\n",
            "\n",
            "--- 4. Generating Embeddings (Using Manual CV2 Load) ---\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/yuva images/Photo_on_24-10-25_at_1.38PM_2.jpg: module 'cv2' has no attribute 'imread'\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/yuva images/Photo_on_24-10-25_at_1.38PM_3.jpg: module 'cv2' has no attribute 'imread'\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/yuva images/Photo_on_24-10-25_at_1.38PM_4.jpg: module 'cv2' has no attribute 'imread'\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/yuva images/Photo_on_24-10-25_at_1.38PM_5.jpg: module 'cv2' has no attribute 'imread'\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/yuva images/Photo_on_24-10-25_at_1.39PM.jpg: module 'cv2' has no attribute 'imread'\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/dinesh images/Photo_on_24-10-25_at_1.37PM.jpg: module 'cv2' has no attribute 'imread'\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/dinesh images/Photo_on_24-10-25_at_1.37PM_2.jpg: module 'cv2' has no attribute 'imread'\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/dinesh images/Photo_on_24-10-25_at_1.37PM_3.jpg: module 'cv2' has no attribute 'imread'\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/dinesh images/Photo_on_24-10-25_at_1.37PM_4.jpg: module 'cv2' has no attribute 'imread'\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/dinesh images/Photo_on_24-10-25_at_1.38PM.jpg: module 'cv2' has no attribute 'imread'\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/vijay images/Photo_on_24-10-25_at_1.33PM.jpg: module 'cv2' has no attribute 'imread'\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/vijay images/Photo_on_24-10-25_at_1.33PM_2.jpg: module 'cv2' has no attribute 'imread'\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/vijay images/Photo_on_24-10-25_at_1.33PM_3.jpg: module 'cv2' has no attribute 'imread'\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/vijay images/Photo_on_24-10-25_at_1.34PM.jpg: module 'cv2' has no attribute 'imread'\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/vijay images/Photo_on_24-10-25_at_1.34PM_2.jpg: module 'cv2' has no attribute 'imread'\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/prudhvi images/Photo_on_24-10-25_at_1.34PM_3.jpg: module 'cv2' has no attribute 'imread'\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/prudhvi images/Photo_on_24-10-25_at_1.34PM_4.jpg: module 'cv2' has no attribute 'imread'\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/prudhvi images/Photo_on_24-10-25_at_1.35PM.jpg: module 'cv2' has no attribute 'imread'\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/prudhvi images/Photo_on_24-10-25_at_1.35PM_2.jpg: module 'cv2' has no attribute 'imread'\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/prudhvi images/Photo_on_24-10-25_at_1.35PM_4.jpg: module 'cv2' has no attribute 'imread'\n",
            "\n",
            "✅ Finished generating raw embeddings. Total successful: 0\n",
            "❌ Aborting export as no embeddings were created.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "1",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# CELL 1: FINAL INSTALLATION & CV2 VERIFICATION\n",
        "# ==============================================================================\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "from IPython import get_ipython\n",
        "\n",
        "print(\"--- Starting Final Dependency Check and Reinstallation ---\")\n",
        "\n",
        "# 1. Aggressively uninstall EVERYTHING to clear paths\n",
        "print(\"Clearing all conflicting packages...\")\n",
        "packages_to_uninstall = [\n",
        "    \"torch\", \"torchvision\", \"torchaudio\", \"numpy\", \"tensorflow\",\n",
        "    \"numba\", \"cupy-cuda12x\", \"opencv-python\", \"opencv-contrib-python\", \"opencv-python-headless\", \"facenet-pytorch\", \"onnx\"\n",
        "]\n",
        "# We pipe output to /dev/null to hide noisy \"Not Installed\" messages\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\"] + packages_to_uninstall + [\"-y\"],\n",
        "                      stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "# 2. Install STABLE, functional versions\n",
        "print(\"Installing core dependencies (torch, numpy, opencv-python, facenet-pytorch)...\")\n",
        "# NumPy must be installed first!\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"numpy==1.26.4\", \"--quiet\"])\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",\n",
        "                      \"torch==2.2.2\", \"torchvision==0.17.2\", \"torchaudio==2.2.2\",\n",
        "                      \"--extra-index-url\", \"https://download.pytorch.org/whl/cu121\",\n",
        "                      \"--quiet\"])\n",
        "\n",
        "# CRITICAL CHANGE: Install standard opencv-python, NOT headless\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"opencv-python\", \"Pillow\", \"--quiet\"])\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"facenet-pytorch==2.5.3\", \"onnx\", \"--quiet\"])\n",
        "\n",
        "print(\"\\nInstallation complete.\")\n",
        "\n",
        "# 3. Handle Colab Runtime Restart\n",
        "print(\"Restarting runtime is CRITICAL to load the new CV2 library...\")\n",
        "time.sleep(3)\n",
        "os.kill(os.getpid(), 9)\n",
        "\n",
        "print(\"Please wait for the runtime to restart before running the main script cell.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OVPV3d2j_cT",
        "outputId": "73fff5cc-dfb5-4030-d8c5-ed3486a0116b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Final Dependency Check and Reinstallation ---\n",
            "Clearing all conflicting packages...\n",
            "Installing core dependencies (torch, numpy, opencv-python, facenet-pytorch)...\n",
            "\n",
            "Installation complete.\n",
            "Restarting runtime is CRITICAL to load the new CV2 library...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# FINAL GUARANTEED PIPELINE SCRIPT (ALL-IN-ONE ROBUST EXECUTION)\n",
        "# ==============================================================================\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# --- 1. Aggressive Dependency Management and Installation ---\n",
        "print(\"--- 1. Starting Aggressive Dependency Management ---\")\n",
        "\n",
        "# 1.1. Aggressively uninstall conflicting packages\n",
        "print(\"Clearing conflicting packages...\")\n",
        "packages_to_uninstall = [\n",
        "    \"torch\", \"torchvision\", \"torchaudio\", \"numpy\", \"tensorflow\",\n",
        "    \"opencv-python\", \"opencv-contrib-python\", \"opencv-python-headless\", \"facenet-pytorch\", \"onnx\",\n",
        "    \"numba\", \"cupy-cuda12x\"\n",
        "]\n",
        "# Use subprocess to run pip commands\n",
        "try:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\"] + packages_to_uninstall + [\"-y\"],\n",
        "                          stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "except:\n",
        "    pass # Ignore errors for packages that aren't installed\n",
        "\n",
        "# 1.2. Install guaranteed stable, functional versions\n",
        "print(\"Installing stable core dependencies...\")\n",
        "# NumPy must be installed first!\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"numpy==1.26.4\", \"--quiet\"])\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",\n",
        "                      \"torch==2.2.2\", \"torchvision==0.17.2\", \"torchaudio==2.2.2\",\n",
        "                      \"--extra-index-url\", \"https://download.pytorch.org/whl/cu121\",\n",
        "                      \"--quiet\"])\n",
        "# Install functional OpenCV and main libraries\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"opencv-python\", \"Pillow\", \"--quiet\"])\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"facenet-pytorch==2.5.3\", \"onnx\", \"--quiet\"])\n",
        "\n",
        "print(\"✅ Installation complete. Loading modules...\")\n",
        "\n",
        "# --- 2. Module Imports and Config ---\n",
        "import torch\n",
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms\n",
        "import torch.onnx\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "from google.colab import drive\n",
        "\n",
        "# Define file paths\n",
        "DATA_DIR = '/content/drive/MyDrive/IMAGE DATASET'\n",
        "EMBEDDINGS_FILE = '/content/drive/MyDrive/visitor_embeddings.pkl'\n",
        "ONNX_MODEL_PATH = '/content/drive/MyDrive/facenet_model.onnx'\n",
        "\n",
        "# Check CV2 health (this should now pass)\n",
        "if not hasattr(cv2, 'imread'):\n",
        "    print(\"❌ FATAL ERROR: CV2 is corrupted despite reinstallation. Please check Colab logs.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Mount Drive and select device\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "except Exception:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "\n",
        "# --- Utility Functions ---\n",
        "def load_and_convert_to_pil(image_path):\n",
        "    # Use cv2.imread - guaranteed to be functional now\n",
        "    img_np = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    if img_np is None:\n",
        "        raise ValueError(f\"CV2 failed to load image. File may be corrupted.\")\n",
        "    img_np = cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB)\n",
        "    return Image.fromarray(img_np)\n",
        "\n",
        "# --------------------------\n",
        "# 3. PIPELINE STEP: FILE CLEANUP AND IMAGE CONVERSION (Standardization)\n",
        "# --------------------------\n",
        "print(\"\\n--- 3. File Cleanup & Aggressive Image Standardization ---\")\n",
        "valid_image_count = 0\n",
        "current_dir_valid = os.path.isdir(DATA_DIR)\n",
        "\n",
        "# This loop must be inside the single cell and run successfully\n",
        "for root, _, files in os.walk(DATA_DIR):\n",
        "    for filename in files:\n",
        "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            old_path = os.path.join(root, filename)\n",
        "            # 1. Filename Normalization\n",
        "            new_filename = filename.replace(' ', '_').replace('#', '').replace(' ', '')\n",
        "            new_path = os.path.join(root, new_filename)\n",
        "            if old_path != new_path:\n",
        "                os.rename(old_path, new_path)\n",
        "\n",
        "            # 2. Aggressive Format Conversion (resaving as standard RGB JPEG via PIL)\n",
        "            try:\n",
        "                img = Image.open(new_path)\n",
        "                if img.mode != 'RGB': img = img.convert('RGB')\n",
        "                img.save(new_path, 'JPEG')\n",
        "                valid_image_count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Corrupted file detected: {new_path}. Error: {e}\")\n",
        "                os.rename(new_path, new_path + '.corrupt')\n",
        "\n",
        "if valid_image_count == 0:\n",
        "    print(\"\\n❌ CRITICAL ERROR: NO valid image files found after conversion. ABORTING.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "print(f\"✅ Finished image standardization. {valid_image_count} files processed successfully.\")\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 4. PIPELINE STEP: MODELS INITIALIZATION\n",
        "# --------------------------\n",
        "print(\"\\n--- 4. Models Initialization ---\")\n",
        "mtcnn = MTCNN(image_size=160, margin=14, min_face_size=20, post_process=True, device=device)\n",
        "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 5. PIPELINE STEP: GENERATE EMBEDDINGS (THE CORE PROCESS)\n",
        "# --------------------------\n",
        "print(\"\\n--- 5. Generating Embeddings (Using Manual CV2 Load) ---\")\n",
        "all_image_paths = []\n",
        "all_labels = []\n",
        "\n",
        "# Manually collect paths and labels\n",
        "for root, _, files in os.walk(DATA_DIR):\n",
        "    if root != DATA_DIR:\n",
        "        label_name = os.path.basename(root)\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.jpg', '.jpeg', '.png')) and not file.endswith('.corrupt'):\n",
        "                all_image_paths.append(os.path.join(root, file))\n",
        "                all_labels.append(label_name)\n",
        "\n",
        "embeddings_raw = {label: [] for label in set(all_labels)}\n",
        "success_count = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for img_path, name in zip(all_image_paths, all_labels):\n",
        "        try:\n",
        "            # LOAD IMAGE with robust CV2 method\n",
        "            img = load_and_convert_to_pil(img_path)\n",
        "\n",
        "            face_tensor = mtcnn(img)\n",
        "            if face_tensor is not None:\n",
        "                face_tensor_batch = face_tensor.to(device).unsqueeze(0)\n",
        "                embedding = resnet(face_tensor_batch).cpu().numpy()[0]\n",
        "\n",
        "                embeddings_raw[name].append(embedding)\n",
        "                success_count += 1\n",
        "            else:\n",
        "                # Log if face detection fails (e.g., poor quality side-face image)\n",
        "                print(f'⚠️ Warning: No face detected for {img_path}. Skipping.')\n",
        "        except Exception as e:\n",
        "            # This should only catch deep errors like actual file read failure\n",
        "            print(f'❌ CRITICAL FINAL FAILURE processing {img_path}: {e}')\n",
        "\n",
        "print(f'\\n✅ Finished generating raw embeddings. Total successful: {success_count}')\n",
        "if success_count == 0:\n",
        "    print(\"❌ Aborting export as no embeddings were created.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# --------------------------\n",
        "# 6. PIPELINE STEP: CREATE & SAVE VISITOR DATABASE (PKL)\n",
        "# --------------------------\n",
        "visitor_database = {}\n",
        "for name, emb_list in embeddings_raw.items():\n",
        "    if len(emb_list) > 0:\n",
        "        mean_embedding = np.mean(emb_list, axis=0)\n",
        "        visitor_database[name] = mean_embedding / np.linalg.norm(mean_embedding)\n",
        "\n",
        "try:\n",
        "    with open(EMBEDDINGS_FILE, 'wb') as f:\n",
        "        pickle.dump(visitor_database, f)\n",
        "    print(f'\\n--- 6. Final Visitor Database (PKL) ---')\n",
        "    print(f'Database saved to: {EMBEDDINGS_FILE}')\n",
        "except Exception as e:\n",
        "    print(f'❌ ERROR: Could not save PKL file to Drive: {e}')\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 7. PIPELINE STEP: EXPORT MODEL TO ONNX\n",
        "# --------------------------\n",
        "resnet.eval().cpu()\n",
        "dummy_input = torch.randn(1, 3, 160, 160)\n",
        "\n",
        "try:\n",
        "    torch.onnx.export(resnet, dummy_input, ONNX_MODEL_PATH, opset_version=12, do_constant_folding=True,\n",
        "                      input_names=['input'], output_names=['output'],\n",
        "                      dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})\n",
        "    print(f'\\n--- 7. ONNX Model Export ---')\n",
        "    print(f'✅ Model exported to ONNX: {ONNX_MODEL_PATH}')\n",
        "except Exception as e:\n",
        "    print(f'❌ CRITICAL ERROR: Failed to export ONNX model: {e}')\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# FINAL DEPLOYMENT ASSETS\n",
        "# --------------------------\n",
        "print('\\n==============================================================================')\n",
        "print('DEPLOYMENT ASSETS CREATED SUCCESSFULLY!')\n",
        "print('1. VISITOR DATABASE (PKL): Ready for comparison logic on Jetson Nano.')\n",
        "print('2. INFERENCE MODEL (ONNX): Ready for TensorRT optimization on Jetson Nano.')\n",
        "print('==============================================================================')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "z8G_xvwLlats",
        "outputId": "983ee693-e0fd-46be-da55-f4f1bd397582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Starting Aggressive Dependency Management ---\n",
            "Clearing conflicting packages...\n",
            "Installing stable core dependencies...\n",
            "✅ Installation complete. Loading modules...\n",
            "Mounted at /content/drive\n",
            "\n",
            "--- 3. File Cleanup & Aggressive Image Standardization ---\n",
            "✅ Finished image standardization. 20 files processed successfully.\n",
            "\n",
            "--- 4. Models Initialization ---\n",
            "\n",
            "--- 5. Generating Embeddings (Using Manual CV2 Load) ---\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/yuvanew/YUVA4.jpeg: Could not infer dtype of numpy.uint8\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/yuvanew/YUVA5.jpeg: Could not infer dtype of numpy.uint8\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/yuvanew/YUVA3.jpeg: Could not infer dtype of numpy.uint8\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/yuvanew/YUVA1.jpeg: Could not infer dtype of numpy.uint8\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/yuvanew/YUVA2.jpeg: Could not infer dtype of numpy.uint8\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/dineshnew/dinesh4.jpeg: Could not infer dtype of numpy.uint8\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/dineshnew/dinesh1.jpeg: Could not infer dtype of numpy.uint8\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/dineshnew/dinesh2.jpeg: Could not infer dtype of numpy.uint8\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/dineshnew/dinesh3.jpeg: Could not infer dtype of numpy.uint8\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/dineshnew/dinesh5.jpeg: Could not infer dtype of numpy.uint8\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/vijaynew/vijay3.jpeg: Could not infer dtype of numpy.uint8\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/vijaynew/vijay1.jpeg: Could not infer dtype of numpy.uint8\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/vijaynew/vijaj2.jpeg: Could not infer dtype of numpy.uint8\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/vijaynew/vijay5.jpeg: Could not infer dtype of numpy.uint8\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/vijaynew/vijay4.jpeg: Could not infer dtype of numpy.uint8\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/prudhvinew/prudhvi3.jpeg: Could not infer dtype of numpy.uint8\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/prudhvinew/prudhvi1.jpeg: Could not infer dtype of numpy.uint8\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/prudhvinew/prudhvi5.jpeg: Could not infer dtype of numpy.uint8\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/prudhvinew/prudhvi2.jpeg: Could not infer dtype of numpy.uint8\n",
            "❌ CRITICAL FINAL FAILURE processing /content/drive/MyDrive/IMAGE DATASET/prudhvinew/prudhvi4.jpeg: Could not infer dtype of numpy.uint8\n",
            "\n",
            "✅ Finished generating raw embeddings. Total successful: 0\n",
            "❌ Aborting export as no embeddings were created.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "1",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# FINAL PIPELINE: OPENCV DNN FACE RECOGNITION ASSET GENERATION\n",
        "# This script uses OpenCV's robust pre-trained models for detection and recognition.\n",
        "# ==============================================================================\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import zipfile\n",
        "import time\n",
        "import requests\n",
        "import io\n",
        "\n",
        "# --- 1. Aggressive Dependency Management and Installation ---\n",
        "print(\"--- 1. Starting Dependency Management and OpenCV Installation ---\")\n",
        "\n",
        "# 1.1. Aggressively uninstall conflicting packages (especially PyTorch components)\n",
        "packages_to_uninstall = [\n",
        "    \"torch\", \"torchvision\", \"torchaudio\", \"facenet-pytorch\", \"onnx\",\n",
        "    \"numpy\", \"opencv-python\", \"opencv-contrib-python\", \"opencv-python-headless\"\n",
        "]\n",
        "try:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\"] + packages_to_uninstall + [\"-y\"],\n",
        "                          stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# 1.2. Install stable, functional versions (NumPy, OpenCV)\n",
        "print(\"Installing stable core dependencies...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"numpy==1.26.4\", \"--quiet\"])\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"opencv-python==4.9.0.80\", \"Pillow\", \"--quiet\"])\n",
        "\n",
        "print(\"✅ Installation complete. Loading modules...\")\n",
        "\n",
        "# --- 2. Module Imports and Config ---\n",
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "\n",
        "# Define file paths (Adjust ZIP_FILE_PATH and ZIP_INNER_FOLDER_NAME)\n",
        "ZIP_FILE_PATH = '/content/drive/MyDrive/visitor_data.zip' # Path to your uploaded ZIP file\n",
        "EXTRACT_DIR = '/content/local_data'\n",
        "# Assuming the zip extracts to a folder named 'CLEAN_DATASET' containing your visitor folders\n",
        "DATA_DIR = os.path.join(EXTRACT_DIR, 'CLEAN_DATASET')\n",
        "EMBEDDINGS_FILE = '/content/drive/MyDrive/visitor_embeddings_opencv.pkl'\n",
        "\n",
        "# --- OpenCV Model Weights Download (Required for DNN) ---\n",
        "# Face Detection Model (SSD MobileNet V1)\n",
        "PROTOTXT = \"deploy.prototxt\"\n",
        "MODEL = \"res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "if not os.path.exists(PROTOTXT):\n",
        "    print(\"Downloading Caffe Face Detection Model...\")\n",
        "    # These are standard Caffe model links for face detection\n",
        "    r = requests.get('https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt', allow_redirects=True)\n",
        "    open(PROTOTXT, 'wb').write(r.content)\n",
        "    r = requests.get('https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel', allow_redirects=True)\n",
        "    open(MODEL, 'wb').write(r.content)\n",
        "# Deep Learning Face Recognizer (Feature Extractor)\n",
        "RECOGNIZER_MODEL = \"res_model.t7\"\n",
        "if not os.path.exists(RECOGNIZER_MODEL):\n",
        "    print(\"Downloading Face Recognition Model...\")\n",
        "    # This is a standard OpenCV deep learning face recognition model (ResNet based)\n",
        "    r = requests.get('https://github.com/opencv/opencv_extra/raw/master/testdata/dnn/face_recognizer_v1_0/res_model.t7', allow_redirects=True)\n",
        "    open(RECOGNIZER_MODEL, 'wb').write(r.content)\n",
        "print(\"✅ OpenCV models downloaded.\")\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 3. PIPELINE STEP: DATA EXTRACTION (ZIP Loading)\n",
        "# --------------------------\n",
        "print(\"\\n--- 3. Data Extraction (Bypassing Drive Mount) ---\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    try:\n",
        "        os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
        "        with zipfile.ZipFile(ZIP_FILE_PATH, 'r') as zip_ref:\n",
        "            zip_ref.extractall(EXTRACT_DIR)\n",
        "        print(f\"✅ Data extracted to local path: {DATA_DIR}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ CRITICAL ERROR: Failed to extract ZIP file. Check if {ZIP_FILE_PATH} exists.\")\n",
        "        print(f\"Error: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 4. PIPELINE STEP: MODELS INITIALIZATION\n",
        "# --------------------------\n",
        "print(\"\\n--- 4. Models Initialization ---\")\n",
        "# Face Detector (Caffe)\n",
        "face_detector = cv2.dnn.readNetFromCaffe(PROTOTXT, MODEL)\n",
        "# Face Recognizer (Torch/ResNet)\n",
        "face_recognizer = cv2.dnn.readNetFromTorch(RECOGNIZER_MODEL)\n",
        "print('✅ OpenCV DNN Models initialized.')\n",
        "\n",
        "# --------------------------\n",
        "# 5. PIPELINE STEP: GENERATE EMBEDDINGS (THE CORE PROCESS)\n",
        "# --------------------------\n",
        "print(\"\\n--- 5. Generating Embeddings ---\")\n",
        "\n",
        "# Utility function for face detection and extraction\n",
        "def get_face_embedding(image_path, confidence_threshold=0.5):\n",
        "    img = cv2.imread(image_path)\n",
        "    (h, w) = img.shape[:2]\n",
        "\n",
        "    # Create a 300x300 blob and run detection\n",
        "    blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
        "    face_detector.setInput(blob)\n",
        "    detections = face_detector.forward()\n",
        "\n",
        "    # Ensure at least one face is detected\n",
        "    if detections.shape[2] > 0 and detections[0, 0, 0, 2] > confidence_threshold:\n",
        "        i = 0 # Take the first and largest face detected\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "        # Extract the face ROI (Region of Interest)\n",
        "        face = img[startY:endY, startX:endX]\n",
        "        if face.shape[0] < 20 or face.shape[1] < 20: # Skip if face is too small\n",
        "             return None\n",
        "\n",
        "        # Generate a 96x96 blob for the recognition model\n",
        "        face_blob = cv2.dnn.blobFromImage(face, 1.0/255, (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
        "\n",
        "        # Generate the embedding (feature vector)\n",
        "        face_recognizer.setInput(face_blob)\n",
        "        embedding = face_recognizer.forward() # 128-dimensional vector\n",
        "\n",
        "        return embedding.flatten()\n",
        "    return None\n",
        "\n",
        "# Manually collect paths and labels from the local, extracted folder\n",
        "all_image_paths = []\n",
        "all_labels = []\n",
        "for root, _, files in os.walk(DATA_DIR):\n",
        "    if root != DATA_DIR:\n",
        "        label_name = os.path.basename(root)\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                all_image_paths.append(os.path.join(root, file))\n",
        "                all_labels.append(label_name)\n",
        "\n",
        "embeddings_raw = {label: [] for label in set(all_labels)}\n",
        "success_count = 0\n",
        "\n",
        "for img_path, name in zip(all_image_paths, all_labels):\n",
        "    try:\n",
        "        embedding = get_face_embedding(img_path)\n",
        "\n",
        "        if embedding is not None:\n",
        "            embeddings_raw[name].append(embedding)\n",
        "            success_count += 1\n",
        "        else:\n",
        "            print(f'⚠️ Warning: No face detected in {name} image: {os.path.basename(img_path)}. Skipping.')\n",
        "    except Exception as e:\n",
        "        print(f'❌ CRITICAL FAILURE processing {img_path}: {e}')\n",
        "\n",
        "print(f'\\n✅ Finished generating raw embeddings. Total successful: {success_count}')\n",
        "if success_count == 0:\n",
        "    print(\"❌ Aborting export as no embeddings were created.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 6. PIPELINE STEP: CREATE & SAVE VISITOR DATABASE (PKL)\n",
        "# --------------------------\n",
        "visitor_database = {}\n",
        "for name, emb_list in embeddings_raw.items():\n",
        "    if len(emb_list) > 0:\n",
        "        mean_embedding = np.mean(emb_list, axis=0)\n",
        "        # Normalization is crucial for Cosine Similarity\n",
        "        visitor_database[name] = mean_embedding / np.linalg.norm(mean_embedding)\n",
        "\n",
        "try:\n",
        "    with open(EMBEDDINGS_FILE, 'wb') as f:\n",
        "        pickle.dump(visitor_database, f)\n",
        "    print(f'\\n--- 6. Final Visitor Database (PKL) ---')\n",
        "    print(f'Database saved to: {EMBEDDINGS_FILE}')\n",
        "except Exception as e:\n",
        "    print(f'❌ ERROR: Could not save PKL file to Drive: {e}')\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 7. PIPELINE STEP: FINAL DEPLOYMENT ASSETS (No ONNX export for this model)\n",
        "# --------------------------\n",
        "# NOTE: OpenCV DNN models (Caffe/Torch) often perform well on the Jetson Nano\n",
        "# without explicit ONNX/TensorRT conversion, relying on optimized JetPack libraries.\n",
        "# The Jetson Nano script will load the .caffemodel, .prototxt, and .t7 files directly.\n",
        "\n",
        "print('\\n==============================================================================')\n",
        "print('DEPLOYMENT ASSETS CREATED SUCCESSFULLY!')\n",
        "print('The Jetson Nano requires 3 model files and 1 database file:')\n",
        "print(f'1. VISITOR DATABASE (PKL): {EMBEDDINGS_FILE}')\n",
        "print(f'2. FACE DETECTOR WEIGHTS: {MODEL}')\n",
        "print(f'3. FACE DETECTOR ARCHITECTURE: {PROTOTXT}')\n",
        "print(f'4. FACE RECOGNIZER MODEL: {RECOGNIZER_MODEL}')\n",
        "print('Copy these four files to your Jetson Nano for real-time inference.')\n",
        "print('==============================================================================')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RG2Dh7UlvJJE",
        "outputId": "435b2f44-e517-4f07-9d83-e35245e6bfd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Starting Dependency Management and OpenCV Installation ---\n",
            "Installing stable core dependencies...\n",
            "✅ Installation complete. Loading modules...\n",
            "Downloading Caffe Face Detection Model...\n",
            "Downloading Face Recognition Model...\n",
            "✅ OpenCV models downloaded.\n",
            "\n",
            "--- 3. Data Extraction (Bypassing Drive Mount) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "❌ CRITICAL ERROR: Failed to extract ZIP file. Check if /content/drive/MyDrive/visitor_data.zip exists.\n",
            "Error: [Errno 2] No such file or directory: '/content/drive/MyDrive/visitor_data.zip'\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-1267009076.py\", line 78, in <cell line: 0>\n",
            "    with zipfile.ZipFile(ZIP_FILE_PATH, 'r') as zip_ref:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/zipfile/__init__.py\", line 1352, in __init__\n",
            "    self.fp = io.open(file, filemode)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/visitor_data.zip'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-1267009076.py\", line 84, in <cell line: 0>\n",
            "    sys.exit(1)\n",
            "SystemExit: 1\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1769, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1701, in getframeinfo\n",
            "    lineno = frame.f_lineno\n",
            "             ^^^^^^^^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'f_lineno'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1267009076.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEXTRACT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZIP_FILE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEXTRACT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1351\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/visitor_data.zip'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1267009076.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 1",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    }
  ]
}